# Plan : Optimisation de la Performance

**Cr√©√©** : 24 Janvier 2026
**Mis √† jour** : 24 Janvier 2026
**Objectif** : Fluidit√© UX, √©liminer freezes/hangs caus√©s par traitements backend
**Priorit√© principale** : Lenteurs sur analyses d'emails
**Focus** : Backend (quick wins) ‚Äî Frontend report√© apr√®s refactoring UI

---

## D√©cisions prises

- [x] Focus sur le **backend** pour cette session (cause des freezes)
- [x] T√¢ches **frontend report√©es** apr√®s le plan de refactoring UI en cours
- [x] Ajout **profiling CPU py-spy** pour analyse approfondie
- [x] Exploiter les **logs `[PERF]`** existants avant d'ajouter des outils
- [x] Plans **s√©par√©s mais s√©quenc√©s** (perf backend ‚Üí refactoring UI ‚Üí perf frontend)

---

## Vue d'ensemble

L'architecture Scapin est d√©j√† bien optimis√©e (cache multi-niveaux, async, d√©duplication O(N)).
Ce plan cible les **goulots d'√©tranglement restants**, particuli√®rement sur l'analyse multi-pass.

**Coupable probable** : Context search synchrone pendant l'analyse multi-pass. Chaque email d√©clenche des recherches vectorielles bloquantes.

---

## Phase 0 ‚Äî Setup Outils

### #12 Installer py-spy

**Commandes** :
```bash
# Installation
pip install py-spy

# V√©rification
py-spy --version
```

**Note macOS** : py-spy peut n√©cessiter des permissions suppl√©mentaires (SIP). Si erreur "Operation not permitted" :
- Lancer avec `sudo py-spy`
- Ou d√©sactiver SIP temporairement (d√©conseill√© en prod)

**Action** : Ajouter √† `requirements-dev.txt` si non pr√©sent

---

## Phase 1 ‚Äî Profiling & Baseline

### #10 √âtablir baseline de performance

**Objectif** : Mesurer l'√©tat actuel avant optimisations

**M√©triques √† capturer** :

| Zone | M√©triques | Outil |
|------|-----------|-------|
| Analyse emails | Temps multi-pass par email | Logs `[PERF]` existants |
| Context search | Temps par recherche entit√© | `time.perf_counter()` |
| Notes loading | Temps startup avec N notes | Timer custom |
| API Backend | Temps r√©ponse endpoints cl√©s | Logs timing |

**Livrable** : Document baseline chiffr√©e dans `docs/plans/performance-baseline.md`

---

### #11 Profiling CPU avec py-spy

**D√©pend de** : #12

**Outil** : py-spy (profiling CPU sans overhead, pas besoin de modifier le code)

**Cibles √† profiler** :
1. Pipeline Four Valets (Grimaud ‚Üí Bazin ‚Üí Planchet ‚Üí Mousqueton)
2. Context search pendant analyse
3. Recherche vectorielle FAISS
4. Lecture notes depuis iCloud

**Commandes** :
```bash
# Profiling en temps r√©el (voir o√π le CPU passe son temps)
py-spy top --pid <PID_BACKEND>

# Flamegraph pour analyse d√©taill√©e
py-spy record -o profile.svg --pid <PID_BACKEND>

# Profiler pendant une analyse d'email
py-spy record -o analysis-profile.svg -- python -c "from src.sancho import analyze_email; ..."
```

**Livrable** : Flamegraph SVG identifiant les hotspots CPU

---

## Phase 2 ‚Äî Quick Wins Backend (Haute priorit√©)

### #4 Impl√©menter cache pour context search entit√©s ‚≠ê PRIORIT√â

**Fichier** : `src/sancho/context_searcher.py`

**Probl√®me** : Pipeline 4 Valets r√©ex√©cute context search pour chaque email. M√™me entit√©s (personnes, projets) recherch√©es r√©p√©titivement.

**Solution** :
- Cache r√©sultats par entity (personnes, projets)
- TTL 15min pour entit√©s stables
- R√©utilisation contexte entre emails similaires

**Impact estim√©** : ~20% gains sur analyse multi-pass

---

### #3 Ajouter early-stop aux adapters email/calendar

**Fichiers** :
- `src/passepartout/cross_source/adapters/email_adapter.py`
- `src/passepartout/cross_source/adapters/base.py`

**Probl√®me** : Pas de filtrage serveur-side, scan complet m√™me si quota atteint

**Solution** :
- Early-stopping si r√©sultats >= max_results
- Offset/limit dans requ√™tes
- Arr√™t scan d√®s quota atteint

---

### #2 R√©duire thread pool note loading (32 ‚Üí 8 workers)

**Fichier** : `src/passepartout/note_manager.py:1723-1731`

**Probl√®me** : `max_workers = min(32, ...)` = surcharge I/O, context switching overhead

**Solution** : R√©duire √† `max_workers = min(8, len(files_to_load))`

**Effort** : 5 minutes ‚Äî Quick win imm√©diat

---

### #5 Ajouter batch_search() √† VectorStore

**Fichier** : `src/passepartout/entity_search.py`

**D√©pend de** : #4

**Solution** : Grouper 10-20 requ√™tes FAISS en une seule, r√©duire overhead embedding

---

## Phase 3 ‚Äî Tests & Validation

### #16 Valider optimisations avec tests de non-r√©gression

**D√©pend de** : #2, #3, #4

**Objectif** : S'assurer que les optimisations n'introduisent pas de bugs

**Actions** :
1. Ex√©cuter suite de tests existante :
   ```bash
   pytest tests/ -v
   ```
2. Tests E2E :
   ```bash
   cd web && npx playwright test
   ```
3. Test manuel : analyser 10 emails et v√©rifier r√©sultats identiques
4. Comparer r√©sultats d'analyse avant/apr√®s optimisations

**Crit√®res de validation** :
- 0 test √©chou√©
- R√©sultats d'analyse identiques (pas de r√©gression fonctionnelle)
- Performance am√©lior√©e (vs baseline)

---

### #13 Cr√©er tests de performance (benchmarks)

**D√©pend de** : #2, #3, #4

**Objectif** : Tests automatis√©s pour mesurer et pr√©venir les r√©gressions de performance

**Fichiers √† cr√©er** :
- `tests/performance/test_context_search_perf.py`
- `tests/performance/test_note_loading_perf.py`
- `tests/performance/test_multi_pass_analysis_perf.py`

**Contenu** :

| Test | M√©trique | Seuil |
|------|----------|-------|
| Context search (avec cache) | Temps r√©ponse | < 100ms |
| Note loading (1000 notes) | Temps total | < 2s |
| Multi-pass analysis | Temps par email | < 5s |

**Exemple de test** :
```python
import pytest
import time

def test_context_search_cached_performance(context_searcher):
    # Premier appel (cache miss)
    start = time.perf_counter()
    result1 = context_searcher.search("Johan")
    cold_time = time.perf_counter() - start

    # Deuxi√®me appel (cache hit)
    start = time.perf_counter()
    result2 = context_searcher.search("Johan")
    warm_time = time.perf_counter() - start

    assert warm_time < 0.1  # < 100ms avec cache
    assert warm_time < cold_time * 0.5  # Au moins 2x plus rapide
```

**Int√©gration CI** : Ajouter √† GitHub Actions avec seuils d'alerte

---

## Phase 4 ‚Äî Documentation

### #14 R√©diger documentation technique performance

**D√©pend de** : #2, #3, #4, #13

**Fichier** : `docs/technical/performance.md`

**Contenu** :

1. **Architecture de cache**
   - Cache multi-niveaux existant (TTL par source)
   - Nouveau cache context search
   - TTLs et strat√©gies d'invalidation

2. **Optimisations impl√©ment√©es**
   - Thread pool sizing (32 ‚Üí 8)
   - Early-stop adapters
   - Batch search VectorStore
   - D√©duplication O(N)

3. **Profiling**
   - Comment utiliser py-spy
   - Interpr√©tation des flamegraphs
   - Logs `[PERF]` existants et leur format

4. **Bonnes pratiques**
   - Patterns async √† suivre
   - Anti-patterns √† √©viter (N+1, sync blocking, etc.)
   - Checklist performance pour nouvelles features

5. **M√©triques de r√©f√©rence**
   - Baseline document√©e
   - Seuils acceptables par op√©ration
   - Comment mesurer (outils, commandes)

---

### #15 Ajouter guide utilisateur performance/troubleshooting

**D√©pend de** : #14

**Fichier** : `docs/user-guide/performance.md`

**Contenu** :

1. **Comportement normal**
   - Temps attendus pour analyse email (~3-5s)
   - Indicateurs de progression dans l'UI
   - Ce qui se passe en arri√®re-plan

2. **Si Scapin est lent**
   - V√©rifier nombre de notes (> 5000 = impact possible)
   - V√©rifier connexion IMAP (latence r√©seau)
   - Vider le cache si incoh√©rences (`/valets` ‚Üí Reset cache)

3. **Optimiser son usage**
   - Archiver les anciennes notes inutilis√©es
   - Configurer les dossiers email √† ignorer
   - R√©duire la profondeur de recherche contextuelle

4. **Diagnostic**
   - O√π trouver les logs : `data/logs/`
   - M√©triques dans page `/valets`
   - Quand signaler un probl√®me de performance

---

## Phase 5 ‚Äî Frontend (REPORT√â)

> **Report√© apr√®s refactoring UI** ‚Äî Ces t√¢ches seront reprises une fois le refactoring UI termin√© pour √©viter les conflits.

| # | T√¢che | Statut |
|---|-------|--------|
| #1 | Splitter API client monolithique | üîú Apr√®s refactoring UI |
| #6 | Auditer reactivity stores Svelte | üîú Apr√®s refactoring UI |
| #7 | Unifier WebSocket et HTTP polling | üîú Apr√®s refactoring UI |
| #9 | Lazy-load composants charts Valets | üîú Apr√®s refactoring UI |

---

## Phase 6 ‚Äî Infrastructure (Basse priorit√©)

### #8 Ajouter compression Gzip aux r√©ponses API

**Solution** : Middleware Gzip FastAPI

**Statut** : Peut √™tre fait ind√©pendamment, faible priorit√©

---

## D√©pendances

```
#12 (install py-spy)
 ‚îî‚îÄ‚îÄ #11 (profiling CPU)

#10 (baseline) + #11 (profiling CPU)
 ‚îú‚îÄ‚îÄ #2 (thread pool) ‚Üê Quick win imm√©diat
 ‚îú‚îÄ‚îÄ #3 (early-stop adapters)
 ‚îî‚îÄ‚îÄ #4 (cache context search) ‚Üê Plus gros impact
      ‚îî‚îÄ‚îÄ #5 (batch search)

#2, #3, #4 (optimisations)
 ‚îú‚îÄ‚îÄ #16 (tests non-r√©gression)
 ‚îî‚îÄ‚îÄ #13 (tests performance)
      ‚îî‚îÄ‚îÄ #14 (doc technique)
           ‚îî‚îÄ‚îÄ #15 (guide utilisateur)

[REPORT√â apr√®s refactoring UI]
#1 (API client split)
#6 (audit stores) ‚Üí #7 (unify WebSocket)
#9 (lazy-load charts)
```

---

## Outils

### Backend Python
| Outil | Usage | Installation |
|-------|-------|--------------|
| **py-spy** | Profiling CPU, flamegraphs | `pip install py-spy` |
| **Logs `[PERF]`** | D√©j√† en place pour Four Valets | Aucune |
| **`time.perf_counter()`** | Timers pr√©cis hot paths | Natif Python |
| **pytest** | Tests unitaires et performance | D√©j√† install√© |

### Frontend (report√©)
- Lighthouse CI, vite-bundle-visualizer, Chrome DevTools

---

## Ordre d'ex√©cution complet

```
Phase 0 ‚Äî Setup
  1. #12 ‚Äî Installer py-spy

Phase 1 ‚Äî Mesure
  2. #10 ‚Äî √âtablir baseline
  3. #11 ‚Äî Profiling CPU

Phase 2 ‚Äî Optimisations
  4. #2 ‚Äî Thread pool 32‚Üí8 (quick win)
  5. #4 ‚Äî Cache context search (plus gros impact)
  6. #3 ‚Äî Early-stop adapters
  7. #5 ‚Äî Batch search VectorStore

Phase 3 ‚Äî Validation
  8. #16 ‚Äî Tests non-r√©gression
  9. #13 ‚Äî Tests performance

Phase 4 ‚Äî Documentation
  10. #14 ‚Äî Doc technique
  11. #15 ‚Äî Guide utilisateur

Phase 5 ‚Äî Optionnel
  12. #8 ‚Äî Gzip (si temps)

Phase 6 ‚Äî Apr√®s refactoring UI
  13. #1, #6, #7, #9 ‚Äî Optimisations frontend
```

---

## Crit√®res de succ√®s

| M√©trique | Objectif |
|----------|----------|
| **Freezes UX** | Z√©ro hang perceptible |
| **Analyse email** | Am√©lioration mesurable vs baseline |
| **Context search** | Cache hit ratio > 50% |
| **Temps r√©ponse API** | < 200ms p95 |
| **Tests** | 100% pass, 0 r√©gression |
| **Documentation** | Technique + utilisateur compl√®tes |

---

## Livrables

| Livrable | Fichier |
|----------|---------|
| Baseline chiffr√©e | `docs/plans/performance-baseline.md` |
| Flamegraph CPU | `profile.svg` |
| Tests performance | `tests/performance/*.py` |
| Doc technique | `docs/technical/performance.md` |
| Guide utilisateur | `docs/user-guide/performance.md` |

---

## Historique

| Date | Action |
|------|--------|
| 2026-01-24 | Cr√©ation du plan |
| 2026-01-24 | Ajout profiling CPU py-spy (#11) |
| 2026-01-24 | D√©cision : focus backend, frontend report√© apr√®s refactoring UI |
| 2026-01-24 | Ajout installation py-spy (#12), tests (#13, #16), documentation (#14, #15) |
